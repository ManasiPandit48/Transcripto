{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CxZwBMviotK",
        "outputId": "b36ffc5d-7b57-4352-f17b-d8f4c8920275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6fuz27XhH90",
        "outputId": "81d0842a-9aed-4067-99c5-4607b506786f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRrxBcQPntcb",
        "outputId": "a2457764-347a-4274-9815-b672d0ed2185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-b7vj9cqa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-b7vj9cqa\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=fc007a75fdacf1fe834cfff2471fecf141407394d73ab08635c4922c09b20394\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ja1y3kvi/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkXMngY9jtSS",
        "outputId": "346b2547-b6ba-4fc3-8e7f-f44fbdf6d408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path of the audio file: /content/_6201459692.mp3\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Urdu\n",
            "[00:00.000 --> 00:02.000]  Hello\n",
            "[00:02.000 --> 00:03.000]  Hello\n",
            "[00:03.000 --> 00:09.000]  Hello, I am from Department of Administrative Reforms and Public Revenues.\n",
            "[00:09.000 --> 00:11.000]  Can you hear me?\n",
            "[00:11.000 --> 00:13.000]  Yes, tell me.\n",
            "[00:13.000 --> 00:18.000]  Hello, I am from Chidhar City.\n",
            "[00:18.000 --> 00:19.000]  Yes\n",
            "[00:19.000 --> 00:23.000]  Did you judge the case in the CT Gram Portal?\n",
            "[00:23.000 --> 00:25.000]  Where?\n",
            "[00:25.000 --> 00:28.000]  In the CT Gram Portal.\n",
            "[00:28.000 --> 00:30.000]  What did you judge?\n",
            "[00:30.000 --> 00:39.000]  You have judged the case in the Central Board of Interest Taxes and Customs on 15th May.\n",
            "[00:39.000 --> 00:42.000]  By the Public Revenues Portal.\n",
            "[00:42.000 --> 00:43.000]  Yes\n",
            "[00:43.000 --> 00:46.000]  Yes, so the CT Gram has called you. When will you be able to reach?\n",
            "[00:46.000 --> 00:49.000]  Actually, I am traveling now. I am in the train.\n",
            "[00:49.000 --> 00:50.000]  Yes\n",
            "[00:50.000 --> 00:54.000]  So, if I can call you later, it would be better.\n",
            "[00:54.000 --> 00:58.000]  I had already spoken to you earlier and asked you to open it.\n",
            "[00:58.000 --> 01:03.000]  Yes, so your server is not complete. So, I will call you again. Okay sir.\n",
            "[01:03.000 --> 01:11.000]  Sir, your complaint number is 0101550. You have been denied for this. What did you do?\n",
            "[01:11.000 --> 01:13.000]  I am not satisfied.\n",
            "[01:13.000 --> 01:18.000]  You are not satisfied? Okay, I will go to the court and ask for a resolution.\n",
            "[01:18.000 --> 01:20.000]  Are you not satisfied?\n",
            "[01:20.000 --> 01:27.000]  There is no resolution in it. When I sent my problem, I did not get any resolution.\n",
            "[01:27.000 --> 01:35.000]  Okay sir. If I go to the CT Gram, I will follow your complaint from here. Okay sir.\n",
            "[01:35.000 --> 01:39.000]  So, what rating do you want? 4 or 4?\n",
            "[01:39.000 --> 01:40.000]  4, 4, 4.\n",
            "[01:40.000 --> 01:41.000]  4.\n",
            "[01:41.000 --> 01:47.000]  If I go to the CT Gram, I will follow your complaint from here. Okay sir.\n",
            "[01:47.000 --> 01:55.000]  Regarding this, if you want to get a resolution, regarding this, you can file a complaint again and then appeal.\n",
            "[01:55.000 --> 01:56.000]  Sure.\n",
            "[01:56.000 --> 01:58.000]  You will not go to the court, right?\n",
            "[01:58.000 --> 02:00.000]  I will not go to the court now.\n",
            "[02:00.000 --> 02:01.000]  Okay.\n",
            "[02:01.000 --> 02:04.000]  I am still in communication with the court.\n",
            "[02:04.000 --> 02:05.000]  Okay, I will call you again.\n",
            "[02:05.000 --> 02:07.000]  So, I will continue.\n",
            "[02:07.000 --> 02:10.000]  After that, I will think of the next step.\n",
            "[02:10.000 --> 02:11.000]  Okay.\n",
            "[02:11.000 --> 02:12.000]  Okay.\n",
            "[02:12.000 --> 02:16.000]  Manohar sir, so your concern is that you will go to the court today, right?\n",
            "[02:16.000 --> 02:18.000]  I am so grateful to you for this.\n",
            "[02:18.000 --> 02:19.000]  Thank you.\n",
            "[02:19.000 --> 02:20.000]  Thank you.\n",
            "[02:20.000 --> 02:21.000]  You did a good job.\n",
            "Transcription for /content/_6201459692.wav:  Hello Hello Hello, I am from Department of Administrative Reforms and Public Revenues. Can you hear me? Yes, tell me. Hello, I am from Chidhar City. Yes Did you judge the case in the CT Gram Portal? Where? In the CT Gram Portal. What did you judge? You have judged the case in the Central Board of Interest Taxes and Customs on 15th May. By the Public Revenues Portal. Yes Yes, so the CT Gram has called you. When will you be able to reach? Actually, I am traveling now. I am in the train. Yes So, if I can call you later, it would be better. I had already spoken to you earlier and asked you to open it. Yes, so your server is not complete. So, I will call you again. Okay sir. Sir, your complaint number is 0101550. You have been denied for this. What did you do? I am not satisfied. You are not satisfied? Okay, I will go to the court and ask for a resolution. Are you not satisfied? There is no resolution in it. When I sent my problem, I did not get any resolution. Okay sir. If I go to the CT Gram, I will follow your complaint from here. Okay sir. So, what rating do you want? 4 or 4? 4, 4, 4. 4. If I go to the CT Gram, I will follow your complaint from here. Okay sir. Regarding this, if you want to get a resolution, regarding this, you can file a complaint again and then appeal. Sure. You will not go to the court, right? I will not go to the court now. Okay. I am still in communication with the court. Okay, I will call you again. So, I will continue. After that, I will think of the next step. Okay. Okay. Manohar sir, so your concern is that you will go to the court today, right? I am so grateful to you for this. Thank you. Thank you. You did a good job.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Old Code\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "def convert_to_wav(audio_file):\n",
        "    # Convert audio file to WAV format\n",
        "    sound = AudioSegment.from_file(audio_file)\n",
        "    wav_file = os.path.splitext(audio_file)[0] + \".wav\"\n",
        "    sound.export(wav_file, format=\"wav\")\n",
        "    return wav_file\n",
        "\n",
        "def transcribe_audio_to_english(audio_file):\n",
        "    try:\n",
        "        model = whisper.load_model(\"large-v3\")\n",
        "        result = model.transcribe(audio_file, fp16=False, task='translate', verbose=True)\n",
        "        return result[\"text\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing {audio_file}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_file = input(\"Enter the path of the audio file: \")\n",
        "\n",
        "    if os.path.exists(audio_file):\n",
        "        if audio_file.lower().endswith(('.mp3', '.wav', '.ogg')):\n",
        "            if audio_file.lower().endswith('.mp3'):\n",
        "                audio_file = convert_to_wav(audio_file)\n",
        "            transcription = transcribe_audio_to_english(audio_file)\n",
        "            if transcription:\n",
        "                print(f\"Transcription for {audio_file}: {transcription}\")\n",
        "            else:\n",
        "                print(f\"Failed to transcribe {audio_file}.\")\n",
        "            if audio_file.lower().endswith('.wav'):\n",
        "                os.remove(audio_file)  # Remove temporary WAV file\n",
        "        else:\n",
        "            print(f\"Unsupported audio format: {audio_file}\")\n",
        "    else:\n",
        "        print(\"File not found. Please provide a valid file path.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z9eiGFAi4xgO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}